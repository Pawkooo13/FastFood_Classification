{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Celem projektu jest klasyfikacja zdjęć fast foodów. Dane składają się ze zdjęć 10 kategorii: burger, donut, hot dog, pizza, sandwich, baked potato, cripsy chicken, fries, taco, taqutio. ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\nimport math\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom keras.utils import load_img\nfrom keras.utils import img_to_array\nfrom keras.models import load_model\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import LearningRateScheduler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2023-05-18T13:57:49.434932Z","iopub.execute_input":"2023-05-18T13:57:49.435650Z","iopub.status.idle":"2023-05-18T13:57:56.922994Z","shell.execute_reply.started":"2023-05-18T13:57:49.435615Z","shell.execute_reply":"2023-05-18T13:57:56.922036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = '/kaggle/input/fast-food-classification-dataset/Fast Food Classification V2'","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:47.000545Z","iopub.execute_input":"2023-05-18T14:00:47.001270Z","iopub.status.idle":"2023-05-18T14:00:47.005792Z","shell.execute_reply.started":"2023-05-18T14:00:47.001238Z","shell.execute_reply":"2023-05-18T14:00:47.004917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(base_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:47.328110Z","iopub.execute_input":"2023-05-18T14:00:47.329087Z","iopub.status.idle":"2023-05-18T14:00:47.343491Z","shell.execute_reply.started":"2023-05-18T14:00:47.329043Z","shell.execute_reply":"2023-05-18T14:00:47.342325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = os.path.join(base_path, 'Train')\nval_path = os.path.join(base_path, 'Valid')\ntest_path = os.path.join(base_path, 'Test')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:47.751619Z","iopub.execute_input":"2023-05-18T14:00:47.752558Z","iopub.status.idle":"2023-05-18T14:00:47.758245Z","shell.execute_reply.started":"2023-05-18T14:00:47.752515Z","shell.execute_reply":"2023-05-18T14:00:47.757164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = os.listdir(train_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dane zawierają trzy zbiory: treningowy, testowy i walidacyjny, które składają się odpowiednio z 15000, 1500 oraz 3500 zdjęć różnych rozmiarów. Nie wszystkie zdjęcia są zapisane w jednym formacie. Zostały one zatem przefiltrowane tak aby miały ten sam format pliku – „jpeg”. Wszystkie klasy mają bardzo podobną liczbę zdjęć przez co nie występuje problem z różnymi wielkościami klas. ","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize = (10,5))\n\nfor i in range(1, 11):    \n    index = np.random.randint(len(train_df))\n    \n    image_path = train_df['path'][index]\n    category = train_df['label'][index]\n    \n    image = np.asarray(Image.open(image_path))\n    plt.subplot(2,5,i)\n    plt.imshow(image)\n    plt.axis('off')\n    plt.title(category)\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T09:32:38.794933Z","iopub.execute_input":"2023-05-18T09:32:38.795300Z","iopub.status.idle":"2023-05-18T09:32:40.013816Z","shell.execute_reply.started":"2023-05-18T09:32:38.795272Z","shell.execute_reply":"2023-05-18T09:32:40.012858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Zdjęcia w zbiorze danych są bardzo różne. Niektóre zdjęcia składają się z kilku dań, inne natomiast zawierają napisy bądź ludzi. Są również takie, na których fast food jest bardzo mały – dużą część obrazka  zajmuje tło.","metadata":{}},{"cell_type":"markdown","source":"Do klasyfikacji może posłużyć algorytm KNN. Aby to zrobić trzeba wczytać każde zdjęcie osobno i skonwertować je na listę liczb. Trzeba również zamienić kategorie na odpowiedniki liczbowe. Do tego posłuży LabelEncoder().","metadata":{}},{"cell_type":"code","source":"def get_images_for_KNN(base_path, categories, n_sample):\n    images = []\n    labels = []\n    \n    for category in categories:\n        path = os.path.join(base_path, category)\n        files = os.listdir(path)\n        \n        for i in range(n_sample):\n            img = os.path.join(path, files[i])\n            if img[-4:] == 'jpeg':\n                img = load_img(img, target_size = (256, 256))\n                img = img_to_array(img)\n                images.append(img.flatten())\n                labels.append(category)\n    \n    images = np.vstack(images)\n    \n    return (np.array(images), np.array(labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train = get_images_for_KNN(train_path, labels, 500)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, Y_test = get_images_for_KNN(test_path, labels, 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\nlabels = label_encoder.fit_transform(Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test = label_encoder.transform(Y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN = KNeighborsClassifier(n_neighbors = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN.fit(X_train, labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = KNN.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Y_test, preds, target_names = label_encoder.classes_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(Y_test, preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN10 = KNeighborsClassifier(n_neighbors = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN10.fit(X_train, labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = KNN10.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Y_test, preds, target_names = label_encoder.classes_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(Y_test, preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN20 = KNeighborsClassifier(n_neighbors = 20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN20.fit(X_train, labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = KNN20.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Y_test, preds, target_names = label_encoder.classes_))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(Y_test, preds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN30 = KNeighborsClassifier(n_neighbors = 30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN30.fit(X_train, labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = KNN30.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Y_test, preds, target_names = label_encoder.classes_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(Y_test, preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jak widać uzyskane dokładności na zbiorze testowym są bardzo małe. Wybór takiego algorytmu do rozwiązania problemu klasyfikacji zdjęć nie jest najlepszym pomysłem. ","metadata":{}},{"cell_type":"code","source":"def get_images_for_ANN(base_path, categories, n_sample):\n    images = []\n    labels = []\n    \n    for category in categories:\n        path = os.path.join(base_path, category)\n        files = os.listdir(path)\n        \n        for i in range(n_sample):\n            img = os.path.join(path, files[i])\n            if img[-4:] == 'jpeg':\n                img = load_img(img, target_size = (64, 64))\n                img = img_to_array(img)\n                images.append(img.flatten())\n                labels.append(category)\n    \n    return (np.array(images), np.array(labels))","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:11:47.120064Z","iopub.execute_input":"2023-05-17T22:11:47.120426Z","iopub.status.idle":"2023-05-17T22:11:47.129125Z","shell.execute_reply.started":"2023-05-17T22:11:47.120397Z","shell.execute_reply":"2023-05-17T22:11:47.128077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categories = os.listdir(train_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:11:48.814731Z","iopub.execute_input":"2023-05-17T22:11:48.815757Z","iopub.status.idle":"2023-05-17T22:11:48.826148Z","shell.execute_reply.started":"2023-05-17T22:11:48.815714Z","shell.execute_reply":"2023-05-17T22:11:48.825212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train = get_images_for_ANN(train_path, categories, 500)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:11:49.408328Z","iopub.execute_input":"2023-05-17T22:11:49.409352Z","iopub.status.idle":"2023-05-17T22:12:05.041706Z","shell.execute_reply.started":"2023-05-17T22:11:49.409309Z","shell.execute_reply":"2023-05-17T22:12:05.040571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:05.044045Z","iopub.execute_input":"2023-05-17T22:12:05.044350Z","iopub.status.idle":"2023-05-17T22:12:05.051786Z","shell.execute_reply.started":"2023-05-17T22:12:05.044324Z","shell.execute_reply":"2023-05-17T22:12:05.050959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\nY_train = label_encoder.fit_transform(Y_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:05.053299Z","iopub.execute_input":"2023-05-17T22:12:05.054088Z","iopub.status.idle":"2023-05-17T22:12:05.080591Z","shell.execute_reply.started":"2023-05-17T22:12:05.054041Z","shell.execute_reply":"2023-05-17T22:12:05.079685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:05.082831Z","iopub.execute_input":"2023-05-17T22:12:05.083195Z","iopub.status.idle":"2023-05-17T22:12:05.093090Z","shell.execute_reply.started":"2023-05-17T22:12:05.083165Z","shell.execute_reply":"2023-05-17T22:12:05.091939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val, Y_val = get_images_for_ANN(val_path, categories, 200)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:05.094513Z","iopub.execute_input":"2023-05-17T22:12:05.095131Z","iopub.status.idle":"2023-05-17T22:12:10.995180Z","shell.execute_reply.started":"2023-05-17T22:12:05.095097Z","shell.execute_reply":"2023-05-17T22:12:10.994248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_val = label_encoder.transform(Y_val)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:10.996495Z","iopub.execute_input":"2023-05-17T22:12:10.996921Z","iopub.status.idle":"2023-05-17T22:12:11.010065Z","shell.execute_reply.started":"2023-05-17T22:12:10.996865Z","shell.execute_reply":"2023-05-17T22:12:11.009110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, Y_test = get_images_for_ANN(test_path, categories, 100)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:11.011472Z","iopub.execute_input":"2023-05-17T22:12:11.012063Z","iopub.status.idle":"2023-05-17T22:12:14.104294Z","shell.execute_reply.started":"2023-05-17T22:12:11.012031Z","shell.execute_reply":"2023-05-17T22:12:14.103306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test = label_encoder.transform(Y_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:14.105933Z","iopub.execute_input":"2023-05-17T22:12:14.106305Z","iopub.status.idle":"2023-05-17T22:12:14.112803Z","shell.execute_reply.started":"2023-05-17T22:12:14.106274Z","shell.execute_reply":"2023-05-17T22:12:14.111658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:14.114468Z","iopub.execute_input":"2023-05-17T22:12:14.114795Z","iopub.status.idle":"2023-05-17T22:12:14.128810Z","shell.execute_reply.started":"2023-05-17T22:12:14.114766Z","shell.execute_reply":"2023-05-17T22:12:14.127108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(12288, input_shape = (12288,)),\n    \n    tf.keras.layers.Dense(8192, activation = 'relu'),\n    #tf.keras.layers.Dense(8192, activation = 'relu'),\n    \n    tf.keras.layers.Dense(4096, activation = 'relu'),\n    #tf.keras.layers.Dense(4096, activation = 'relu'),\n    \n    tf.keras.layers.Dense(2056, activation = 'relu'),\n    tf.keras.layers.Dense(1024, activation = 'relu'),\n    tf.keras.layers.Dense(256, activation = 'relu'),\n    tf.keras.layers.Dense(10, activation = 'softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:30:06.351662Z","iopub.execute_input":"2023-05-17T21:30:06.352009Z","iopub.status.idle":"2023-05-17T21:30:06.429494Z","shell.execute_reply.started":"2023-05-17T21:30:06.351980Z","shell.execute_reply":"2023-05-17T21:30:06.428594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:30:08.734762Z","iopub.execute_input":"2023-05-17T21:30:08.735134Z","iopub.status.idle":"2023-05-17T21:30:08.761563Z","shell.execute_reply.started":"2023-05-17T21:30:08.735104Z","shell.execute_reply":"2023-05-17T21:30:08.760869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), optimizer = tf.keras.optimizers.Adam(), metrics = 'accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:30:19.799558Z","iopub.execute_input":"2023-05-17T21:30:19.799915Z","iopub.status.idle":"2023-05-17T21:30:19.814672Z","shell.execute_reply.started":"2023-05-17T21:30:19.799885Z","shell.execute_reply":"2023-05-17T21:30:19.813810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN.fit(X_train, Y_train, batch_size = 5, epochs = 30)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:30:22.774745Z","iopub.execute_input":"2023-05-17T21:30:22.775117Z","iopub.status.idle":"2023-05-17T21:43:25.733941Z","shell.execute_reply.started":"2023-05-17T21:30:22.775084Z","shell.execute_reply":"2023-05-17T21:43:25.732960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taka topologia sieci w ogóle nie była w stanie się nauczyć klasyfikować zdjecia. Bardzo możliwe, że model jest po prostu za mały aby rozwiązać tak skomplikowany problem.","metadata":{}},{"cell_type":"code","source":"es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:14.131252Z","iopub.execute_input":"2023-05-17T22:12:14.131715Z","iopub.status.idle":"2023-05-17T22:12:14.136986Z","shell.execute_reply.started":"2023-05-17T22:12:14.131683Z","shell.execute_reply":"2023-05-17T22:12:14.135728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_v2 = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(12288, input_shape = (12288,)),\n    \n    tf.keras.layers.Dense(8192, activation = 'relu'),\n    \n    tf.keras.layers.Dense(4096, activation = 'relu'),\n    tf.keras.layers.Dense(4096, activation = 'relu'),\n    \n    tf.keras.layers.Dense(2056, activation = 'relu'),\n    tf.keras.layers.Dense(2056, activation = 'relu'),\n    \n    tf.keras.layers.Dense(1024, activation = 'relu'),\n    tf.keras.layers.Dense(256, activation = 'relu'),\n    tf.keras.layers.Dense(10, activation = 'softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:48:54.009416Z","iopub.execute_input":"2023-05-17T21:48:54.009788Z","iopub.status.idle":"2023-05-17T21:48:56.878905Z","shell.execute_reply.started":"2023-05-17T21:48:54.009756Z","shell.execute_reply":"2023-05-17T21:48:56.877986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_v2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:49:00.067467Z","iopub.execute_input":"2023-05-17T21:49:00.068363Z","iopub.status.idle":"2023-05-17T21:49:00.095093Z","shell.execute_reply.started":"2023-05-17T21:49:00.068313Z","shell.execute_reply":"2023-05-17T21:49:00.094360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_v2.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), optimizer = tf.keras.optimizers.Adam(), metrics = 'accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:49:07.107869Z","iopub.execute_input":"2023-05-17T21:49:07.108468Z","iopub.status.idle":"2023-05-17T21:49:07.129824Z","shell.execute_reply.started":"2023-05-17T21:49:07.108431Z","shell.execute_reply":"2023-05-17T21:49:07.128978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = ANN_v2.fit(X_train, Y_train, batch_size = 5, validation_data = (X_val, Y_val), epochs = 30, callbacks = [es])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:49:12.295359Z","iopub.execute_input":"2023-05-17T21:49:12.295707Z","iopub.status.idle":"2023-05-17T21:52:50.782746Z","shell.execute_reply.started":"2023-05-17T21:49:12.295678Z","shell.execute_reply":"2023-05-17T21:52:50.781580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dodanie kilku warstw nie przyniosło żadnych efektów. Czasami zmiana funkcji aktywacji warstw lub zmiana optimizera pomaga uzyskać lepszy rezultat.","metadata":{}},{"cell_type":"code","source":"ANN_v3 = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(12288, input_shape = (12288,)),\n    \n    tf.keras.layers.Dense(8192, activation = 'tanh'),\n    \n    tf.keras.layers.Dense(4096, activation = 'tanh'),\n    tf.keras.layers.Dense(4096, activation = 'tanh'),\n    \n    tf.keras.layers.Dense(2056, activation = 'tanh'),\n    tf.keras.layers.Dense(2056, activation = 'tanh'),\n    \n    tf.keras.layers.Dense(1024, activation = 'tanh'),\n    tf.keras.layers.Dense(1024, activation = 'tanh'),\n    \n    tf.keras.layers.Dense(256, activation = 'tanh'),\n    tf.keras.layers.Dense(64, activation = 'tanh'),\n    tf.keras.layers.Dense(10, activation = 'softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:56:38.703765Z","iopub.execute_input":"2023-05-17T21:56:38.704227Z","iopub.status.idle":"2023-05-17T21:56:38.876953Z","shell.execute_reply.started":"2023-05-17T21:56:38.704188Z","shell.execute_reply":"2023-05-17T21:56:38.875992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_v3.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:56:42.673568Z","iopub.execute_input":"2023-05-17T21:56:42.674051Z","iopub.status.idle":"2023-05-17T21:56:42.702846Z","shell.execute_reply.started":"2023-05-17T21:56:42.674011Z","shell.execute_reply":"2023-05-17T21:56:42.702176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_v3.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), optimizer = tf.keras.optimizers.Adam(), metrics = 'accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:56:50.316767Z","iopub.execute_input":"2023-05-17T21:56:50.317440Z","iopub.status.idle":"2023-05-17T21:56:50.330941Z","shell.execute_reply.started":"2023-05-17T21:56:50.317401Z","shell.execute_reply":"2023-05-17T21:56:50.329598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = ANN_v3.fit(X_train, Y_train, batch_size = 5, validation_data = (X_val, Y_val), epochs = 30, callbacks = [es])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T21:56:54.941059Z","iopub.execute_input":"2023-05-17T21:56:54.941723Z","iopub.status.idle":"2023-05-17T22:01:04.412589Z","shell.execute_reply.started":"2023-05-17T21:56:54.941686Z","shell.execute_reply":"2023-05-17T22:01:04.411714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jak widać, zmiana funkcji aktywacji również nie pomogła. Powyższe modele były uczone na wartościach pixeli obrazka na przedziale [0; 255]. Można spróbować znormalizować dane skalując wartości do przedziału [0; 1].","metadata":{}},{"cell_type":"code","source":"X_train_norm = X_train/255\nX_val_norm = X_val/255","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:22.118007Z","iopub.execute_input":"2023-05-17T22:12:22.118366Z","iopub.status.idle":"2023-05-17T22:12:22.224080Z","shell.execute_reply.started":"2023-05-17T22:12:22.118332Z","shell.execute_reply":"2023-05-17T22:12:22.223023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_NORM = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(12288, input_shape = (12288,)),\n    \n    tf.keras.layers.Dense(8192, activation = 'tanh'),\n    \n    tf.keras.layers.Dense(4096, activation = 'tanh'),\n    tf.keras.layers.Dense(4096, activation = 'tanh'),\n    \n    tf.keras.layers.Dense(2056, activation = 'tanh'),\n    tf.keras.layers.Dense(2056, activation = 'tanh'),\n    \n    tf.keras.layers.Dense(1024, activation = 'tanh'),\n    tf.keras.layers.Dense(1024, activation = 'tanh'),\n    \n    tf.keras.layers.Dense(256, activation = 'tanh'),\n    tf.keras.layers.Dense(64, activation = 'tanh'),\n    tf.keras.layers.Dense(10, activation = 'softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:28.319408Z","iopub.execute_input":"2023-05-17T22:12:28.319768Z","iopub.status.idle":"2023-05-17T22:12:31.031678Z","shell.execute_reply.started":"2023-05-17T22:12:28.319742Z","shell.execute_reply":"2023-05-17T22:12:31.030713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_NORM.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:33.662337Z","iopub.execute_input":"2023-05-17T22:12:33.662697Z","iopub.status.idle":"2023-05-17T22:12:33.692538Z","shell.execute_reply.started":"2023-05-17T22:12:33.662670Z","shell.execute_reply":"2023-05-17T22:12:33.691756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_NORM.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), optimizer = tf.keras.optimizers.Adam(), metrics = 'accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:38.333039Z","iopub.execute_input":"2023-05-17T22:12:38.333693Z","iopub.status.idle":"2023-05-17T22:12:38.354000Z","shell.execute_reply.started":"2023-05-17T22:12:38.333659Z","shell.execute_reply":"2023-05-17T22:12:38.353100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = ANN_NORM.fit(X_train_norm, Y_train, batch_size = 5, validation_data = (X_val_norm, Y_val), epochs = 30, callbacks = [es])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T22:12:41.730842Z","iopub.execute_input":"2023-05-17T22:12:41.731224Z","iopub.status.idle":"2023-05-17T22:17:26.077063Z","shell.execute_reply.started":"2023-05-17T22:12:41.731196Z","shell.execute_reply":"2023-05-17T22:17:26.075703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Również to nie dało żadnych efektów. Nie jest to nic dziwnego, ponieważ problem jest trudny do rozwiązania. Również stosowanie sztucznych sieci neuronowych nie jest najlepszym pomysłem. Wczytując zdjęcia jako listy 1D z wartościami pixeli tracimy m.in. informacje o lokalizacji obiektu na zdjęciu. Pod względem optymalizacji również nie jest to najlepsze podejście. Wyuczenie tego typu sieci wymaga zastosowania bardzo dużej ilości parametrów. Samo wczytanie zdjęcia 64x64x3 wymaga 12288 neuronów. O wiele lepszym podejściem jest zastosowanie konwolucyjnych sieci neuronowych. Zostały one stworzone do ekstrakcji cech zdjęcia, przez co można je wykorzystać do klasyfikacji zdjęć. Ich główną przewagą nad ANN jest redukcja potrzebnych parametrów. ","metadata":{}},{"cell_type":"code","source":"file_paths = []\nlabels = []\n\ncategories = os.listdir(train_path)\n\nfor category in categories:\n    path = os.path.join(train_path, category)\n    for file in os.listdir(path):\n        if file[-4:] == 'jpeg': \n            file_paths.append(os.path.join(path, file))\n            labels.append(category)\n        \ntrain_df = pd.DataFrame({'path' : file_paths, 'label' : labels})","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:01:07.771448Z","iopub.execute_input":"2023-05-18T14:01:07.771799Z","iopub.status.idle":"2023-05-18T14:01:11.806044Z","shell.execute_reply.started":"2023-05-18T14:01:07.771772Z","shell.execute_reply":"2023-05-18T14:01:11.805021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:01:11.808082Z","iopub.execute_input":"2023-05-18T14:01:11.808445Z","iopub.status.idle":"2023-05-18T14:01:11.825859Z","shell.execute_reply.started":"2023-05-18T14:01:11.808403Z","shell.execute_reply":"2023-05-18T14:01:11.824736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_paths = []\nlabels = []\n\ncategories = os.listdir(val_path)\n\nfor category in categories:\n    path = os.path.join(val_path, category)\n    for file in os.listdir(path):\n        if file[-4:] == 'jpeg': \n            file_paths.append(os.path.join(path, file))\n            labels.append(category)\n        \nval_df = pd.DataFrame({'path' : file_paths, 'label' : labels})","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:01:11.827572Z","iopub.execute_input":"2023-05-18T14:01:11.827990Z","iopub.status.idle":"2023-05-18T14:01:14.703623Z","shell.execute_reply.started":"2023-05-18T14:01:11.827958Z","shell.execute_reply":"2023-05-18T14:01:14.702448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:01:14.707477Z","iopub.execute_input":"2023-05-18T14:01:14.709362Z","iopub.status.idle":"2023-05-18T14:01:14.720221Z","shell.execute_reply.started":"2023-05-18T14:01:14.709323Z","shell.execute_reply":"2023-05-18T14:01:14.719223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.groupby(['label']).count().plot.barh(color = 'skyblue', edgecolor = 'black')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T09:32:32.940390Z","iopub.execute_input":"2023-05-18T09:32:32.940734Z","iopub.status.idle":"2023-05-18T09:32:33.278617Z","shell.execute_reply.started":"2023-05-18T09:32:32.940706Z","shell.execute_reply":"2023-05-18T09:32:33.277700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df.groupby(['label']).count().plot.barh(color = 'skyblue', edgecolor = 'black')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T09:32:35.246485Z","iopub.execute_input":"2023-05-18T09:32:35.246862Z","iopub.status.idle":"2023-05-18T09:32:35.545086Z","shell.execute_reply.started":"2023-05-18T09:32:35.246831Z","shell.execute_reply":"2023-05-18T09:32:35.544182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = ImageDataGenerator().flow_from_dataframe(train_df, \n                                                    x_col = 'path',\n                                                    y_col = 'label',\n                                                    target_size=(256,256),\n                                                    color_mode = 'rgb',\n                                                    classes = categories,\n                                                    batch_size = 32, \n                                                    class_mode='categorical')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_generator = ImageDataGenerator().flow_from_dataframe(val_df,\n                                                        x_col = 'path',\n                                                        y_col = 'label',\n                                                        target_size=(256,256),\n                                                        color_mode = 'rgb',\n                                                        classes = categories,\n                                                        batch_size = 32, \n                                                        class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:53:24.955708Z","iopub.execute_input":"2023-05-18T10:53:24.956752Z","iopub.status.idle":"2023-05-18T10:53:26.588608Z","shell.execute_reply.started":"2023-05-18T10:53:24.956712Z","shell.execute_reply":"2023-05-18T10:53:26.587613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters = 32, kernel_size = (11,11), activation = 'relu', input_shape = (256, 256, 3)),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    #tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    #tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units = 1024, activation = 'relu'),\n    tf.keras.layers.Dense(units = 256, activation = 'relu'),\n    tf.keras.layers.Dense(units = 10, activation = 'softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Topologia sieci została dobrana w taki sposób aby uwzględniała dużą powierzchnię tła na obrazkach, dlatego właśnie pierwsza warstwa konwolucyjna ma duży rozmiar filtrów. Pozbywamy się w ten sposób niepotrzebnych informacji. Kolejne warstwy mają coraz mniejsze rozmiary filtrów aby wydobyć jak najwięcej szczegółów na obrazku. Wzrosła przez to również ilość samych filtrów. Pomiędzy kolejnymi warstwami konwolucyjnymi są użyte warstwy MaxPooling, tak aby redukować rozmiary obrazków. Po ekstrakcji cech, gdy rozmiar obrazka jest już bardzo mocno zredukowany, wektor cech przechodzi przez warstwę wypłaszczającą po to aby mógł zostać przepuszczony przez warstwę fully-connected w celu klasyfikacji. ","metadata":{}},{"cell_type":"code","source":"CNN.compile(loss = tf.keras.losses.CategoricalCrossentropy(), optimizer = tf.optimizers.Adam(), metrics = 'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = CNN.fit(train_generator, validation_data = validation_generator, epochs = 50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN.save('fastfood_cnn.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Accuracy vs Validation accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Loss vs Validation loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_images_to_predict(base_path, categories, rescale = False):\n    images = []\n    labels = []\n    \n    for category in categories:\n        path = os.path.join(base_path, category)\n        \n        for img in os.listdir(path):\n            img = os.path.join(path, img)\n            img = load_img(img, target_size = (256, 256))\n            img = img_to_array(img)\n            img = np.expand_dims(img, axis=0)\n            if rescale == True:\n                img = img/255\n            images.append(img)\n            labels.append(category)\n    \n    images = np.vstack(images)\n    \n    return (images, labels)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:01:37.611594Z","iopub.execute_input":"2023-05-18T14:01:37.611946Z","iopub.status.idle":"2023-05-18T14:01:37.620150Z","shell.execute_reply.started":"2023-05-18T14:01:37.611911Z","shell.execute_reply":"2023-05-18T14:01:37.619234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, Y_test = get_images_to_predict(test_path, categories)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:53:44.679059Z","iopub.execute_input":"2023-05-18T10:53:44.679447Z","iopub.status.idle":"2023-05-18T10:53:51.588210Z","shell.execute_reply.started":"2023-05-18T10:53:44.679415Z","shell.execute_reply":"2023-05-18T10:53:51.587243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN = load_model('fastfood_cnn.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = CNN.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def probabilities_to_labels(preds):\n    labels = ['Donut','Sandwich','Hot Dog','Burger','Crispy Chicken','Fries','Baked Potato','Taco','Pizza','Taquito']\n    predictions = []\n\n    for probabilities in preds:\n        index = np.argmax(probabilities)\n        predictions.append(labels[index])\n        \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:01:42.467553Z","iopub.execute_input":"2023-05-18T14:01:42.467901Z","iopub.status.idle":"2023-05-18T14:01:42.476101Z","shell.execute_reply.started":"2023-05-18T14:01:42.467874Z","shell.execute_reply":"2023-05-18T14:01:42.475218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = probabilities_to_labels(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(Y_test, predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm, cmap='Blues', xticklabels = categories, yticklabels = categories, annot = True, cbar = False, fmt=\".1f\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_true = Y_test, y_pred = predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uzyskany wynik nie jest zadowalający, natomiast jest lepszy od wyników KNN i ANN. Sieć bardzo szybko się przeuczyła.","metadata":{}},{"cell_type":"code","source":"train_datagen_norm = ImageDataGenerator(rescale = 1./255)\n\ntrain_generator_norm = train_datagen_norm.flow_from_dataframe(train_df, \n                                                    x_col = 'path',\n                                                    y_col = 'label',\n                                                    target_size=(256,256),\n                                                    color_mode = 'rgb',\n                                                    batch_size = 32,\n                                                    classes = categories,\n                                                    class_mode='categorical')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_datagen_norm = ImageDataGenerator(rescale = 1./255)\n\nvalidation_generator_norm = val_datagen_norm.flow_from_dataframe(val_df, \n                                                        x_col = 'path',\n                                                        y_col = 'label',\n                                                        target_size=(256,256),\n                                                        color_mode = 'rgb',\n                                                        batch_size = 32,\n                                                        classes = categories,\n                                                        class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:01:51.072625Z","iopub.execute_input":"2023-05-18T14:01:51.072975Z","iopub.status.idle":"2023-05-18T14:01:52.656352Z","shell.execute_reply.started":"2023-05-18T14:01:51.072947Z","shell.execute_reply":"2023-05-18T14:01:52.655469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Norm = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters = 32, kernel_size = (11,11), activation = 'relu', input_shape = (256, 256, 3)),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    #tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    #tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units = 1024, activation = 'relu'),\n    tf.keras.layers.Dense(units = 256, activation = 'relu'),\n    tf.keras.layers.Dense(units = 10, activation = 'softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Norm.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Norm.compile(loss = 'CategoricalCrossentropy', optimizer = tf.optimizers.Adam(), metrics = 'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = CNN_Norm.fit(train_generator_norm, validation_data = validation_generator_norm, epochs = 50, callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Accuracy vs Validation accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Loss vs Validation loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Norm.save('fastfood_cnn_norm.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Norm = load_model('fastfood_cnn_norm.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, Y_test = get_images_to_predict(test_path, categories, rescale = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = CNN_Norm.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = probabilities_to_labels(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_true = Y_test, y_pred = predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm, cmap='Blues', xticklabels = categories, yticklabels = categories, annot = True, cbar = False, fmt=\".1f\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Zastosowanie normalizacji tylko pogorszyło wynik. W celu poprawienia dokładności sieci i pozbycia się overfittingu można zastosować kilka technik. Kolejne modele będę opierać się o warstwy Dropout oraz BatchNormalization.","metadata":{}},{"cell_type":"code","source":"CNN_Dropout = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters = 32, kernel_size = (11,11), activation = 'relu', input_shape = (256, 256, 3)),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    #tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    #tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(units = 1024, activation = 'relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(units = 256, activation = 'relu'),\n    tf.keras.layers.Dense(units = 10, activation = 'softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Dropout.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Dropout.compile(loss = 'CategoricalCrossentropy', optimizer = tf.keras.optimizers.Adam(), metrics = 'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = CNN_Dropout.fit(train_generator, validation_data = validation_generator, epochs = 50, callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Dropout.save('fastfood_cnn_dropout.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Accuracy vs Validation accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Loss vs Validation loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, Y_test = get_images_to_predict(test_path, categories, rescale = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = CNN_Dropout.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = probabilities_to_labels(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(Y_test, predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm, cmap='Blues', xticklabels = categories, yticklabels = categories, annot = True, cbar = False, fmt=\".1f\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_true = Y_test, y_pred = predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dodanie warstw Dropout pomogło uzyskać kilka punktów procentowych dokładności więcej.","metadata":{}},{"cell_type":"code","source":"CNN_Batchnorm = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters = 32, kernel_size = (11,11), activation = 'relu', input_shape = (256, 256, 3)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units = 1024, activation = 'relu'),\n    tf.keras.layers.Dense(units = 256, activation = 'relu'),\n    tf.keras.layers.Dense(units = 10, activation = 'softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm.compile(loss = 'CategoricalCrossentropy', optimizer = tf.keras.optimizers.Adam(), metrics = 'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = CNN_Batchnorm.fit(train_generator, validation_data = validation_generator, epochs = 50, callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm.save('fastfood_cnn_batchnorm.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Accuracy vs Validation accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Loss vs Validation loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, Y_test = get_images_to_predict(test_path, categories, rescale = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = CNN_Batchnorm.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = probabilities_to_labels(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(Y_test, predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm, cmap='Blues', xticklabels = categories, yticklabels = categories, annot = True, cbar = False, fmt=\".1f\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(Y_test, predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Zastosowanie warstw BatchNormalization dało jeszcze lepszy rezultat. Dokładność modelu wzrosła do 53%. Mimo to dalej występuje problem z nadmiernym dopasowanie. Aby temu zapobiec można zastosować augmentację danych. Polega ona na zastosowaniu różnych przekształceń na wejściowych obrazkach. W skład przekształceń wchodzą m.in.: rotacja, odwrócenie w pionie lub poziomie lub przesunięcie. Zastosowanie augmentacji spowoduje, że model podczas uczenia nie zobaczy tych samych obrazków przez co szansa na przeuczenie maleje.","metadata":{}},{"cell_type":"code","source":"train_datagen_aug = ImageDataGenerator(rotation_range = 30,\n                                       width_shift_range = 0.1,\n                                       height_shift_range = 0.1,\n                                       fill_mode = 'nearest',\n                                       zoom_range = 0.1,\n                                       horizontal_flip = True,\n                                       vertical_flip = True)\n\ntrain_generator_aug = train_datagen_aug.flow_from_dataframe(train_df,\n                                                    x_col = 'path',\n                                                    y_col = 'label',\n                                                    target_size=(256,256),\n                                                    color_mode = 'rgb',\n                                                    classes = categories,\n                                                    batch_size = 32, \n                                                    class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:54:12.861785Z","iopub.execute_input":"2023-05-18T10:54:12.862179Z","iopub.status.idle":"2023-05-18T10:54:22.769001Z","shell.execute_reply.started":"2023-05-18T10:54:12.862136Z","shell.execute_reply":"2023-05-18T10:54:22.768062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = np.expand_dims(image, axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nfor batch in train_datagen_aug.flow(image, batch_size = 1):\n    plt.figure(i)\n    imgplot = plt.imshow(tf.keras.utils.array_to_img(batch[0]))\n    plt.axis('off')\n    i += 1\n    if i % 4 == 0:\n        break\n        \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm_Aug = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters = 32, kernel_size = (11,11), activation = 'relu', input_shape = (256, 256, 3)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units = 1024, activation = 'relu'),\n    tf.keras.layers.Dense(units = 256, activation = 'relu'),\n    tf.keras.layers.Dense(units = 10, activation = 'softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm_Aug.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm_Aug.compile(loss = 'CategoricalCrossentropy', optimizer = tf.optimizers.Adam(), metrics = 'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = CNN_Batchnorm_Aug.fit(train_generator_aug, validation_data = validation_generator, epochs = 80, callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Accuracy vs Validation accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Loss vs Validation loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm_Aug.save('fastfood_cnn_batchn_aug.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm_Aug = load_model('fastfood_cnn_batchn_aug.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, Y_test = get_images_to_predict(test_path, categories)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = CNN_Batchnorm_Aug.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = probabilities_to_labels(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_true = Y_test, y_pred = predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm, cmap='Blues', xticklabels = categories, yticklabels = categories, annot = True, cbar = False, fmt=\".1f\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(Y_test, predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Powyższe wykresy dalej wskazują na overfitting modelu. Mimo wszystko dokładność predykcji na zbiorze testowym bardzo wzrosła. Wyniosła ona 66%. Niektóre fast foody są bardzo dobrze klasyfikowane. Główny problem stanowią pizza, taquito oraz hot dog.","metadata":{}},{"cell_type":"code","source":"CNN_Dropout_Aug = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters = 32, kernel_size = (11,11), activation = 'relu', input_shape = (256, 256, 3)),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 64, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    #tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    #tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units = 1024, activation = 'relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(units = 256, activation = 'relu'),\n    tf.keras.layers.Dense(units = 10, activation = 'softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Dropout_Aug.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Dropout_Aug.compile(loss = 'CategoricalCrossentropy', optimizer = tf.keras.optimizers.Adam(), metrics = 'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = CNN_Dropout_Aug.fit(train_generator_aug, validation_data = validation_generator, epochs = 80, callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Accuracy vs Validation accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Loss vs Validation loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Dropout_Aug.save('fastfood_cnn_drop_aug.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, Y_test = get_images_to_predict(test_path, labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = CNN_Dropout_Aug.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = probabilities_to_labels(preds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(Y_test, predictions)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm, cmap='Blues', xticklabels = categories, yticklabels = categories, annot = True, cbar = False, fmt=\".1f\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(Y_test, predictions)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"W tym przypadku augmentacja danych nie pomogła uzyskać lepszch efektów.","metadata":{}},{"cell_type":"markdown","source":"Aby ulepszyć model można spróbować dobrać odpowiednie parametry. Jednym z nich jest współczynnik uczenia. Do tego posłuży LearningRateScheduler. Współczynnik uczenia będzie się zmieniał w zależności od danej epoki. Przez kilka epok sieć będzie się uczyć na konkretnym współczynniku, po czym zostanie on odpowiednio zmieniony na kilka kolejnych epok.","metadata":{}},{"cell_type":"code","source":"def step_decay(epoch):\n    initial_lrate = 0.1\n    drop = 0.5\n    epochs_drop = 5.0\n    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n    return lrate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = np.arange(1,50)\nlearning_rate = list(map(lambda epoch: step_decay(epoch), epochs))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, learning_rate, 'o')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.max(learning_rate), np.min(learning_rate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LearningRateScheduler(step_decay)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = CNN_Batchnorm_Aug.fit(train_generator_aug, validation_data = validation_generator, epochs = 50, callbacks = [lr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nl_r = history.history['lr']\n\nepochs = range(len(acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, acc, 'blue')\nplt.plot(epochs, val_acc, 'orange')\nplt.plot(epochs, l_r, 'green')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss, 'blue')\nplt.plot(epochs, val_loss, 'orange')\nplt.plot(epochs, l_r, 'green')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jak widać żaden z współczynników nie wyróżnia się zmniejszeniem wartości funkcji straty ani wzrostem dokładności. Może to wynikać z charakterystyki zastosowanego optimizera. ADAM jest optimizerem adaptywnym. Każdy parametr jest akutalizowany przez indywidualny learning rate, a ten określony podczas inicjacji modelu jest maksymalnym do aktualizacji, zatem stosowanie LearningRateSchedulera nie zawsze może przynieść efekty. Przy stosowaniu tego optimizera głównie określa się inne parametry takie jak: beta_1 i beta_2, które odpowiadają za estymacje pierwszego i drugiego momentu.","metadata":{}},{"cell_type":"code","source":"CNN_Batchnorm_Aug_v2 = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters = 32, kernel_size = (11,11), activation = 'relu', input_shape = (256, 256, 3)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 96, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 96, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units = 1024, activation = 'relu'),\n    tf.keras.layers.Dense(units = 256, activation = 'relu'),\n    tf.keras.layers.Dense(units = 10, activation = 'softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:54:25.820328Z","iopub.execute_input":"2023-05-18T10:54:25.820714Z","iopub.status.idle":"2023-05-18T10:54:28.692257Z","shell.execute_reply.started":"2023-05-18T10:54:25.820682Z","shell.execute_reply":"2023-05-18T10:54:28.691306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm_Aug_v2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:54:31.696273Z","iopub.execute_input":"2023-05-18T10:54:31.696808Z","iopub.status.idle":"2023-05-18T10:54:31.759308Z","shell.execute_reply.started":"2023-05-18T10:54:31.696773Z","shell.execute_reply":"2023-05-18T10:54:31.758575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm_Aug_v2.compile(loss = 'CategoricalCrossentropy', optimizer = tf.keras.optimizers.Adam(), metrics = 'accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:54:35.337829Z","iopub.execute_input":"2023-05-18T10:54:35.338218Z","iopub.status.idle":"2023-05-18T10:54:35.361040Z","shell.execute_reply.started":"2023-05-18T10:54:35.338185Z","shell.execute_reply":"2023-05-18T10:54:35.360120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 8)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:04:10.487890Z","iopub.execute_input":"2023-05-18T14:04:10.488263Z","iopub.status.idle":"2023-05-18T14:04:10.492745Z","shell.execute_reply.started":"2023-05-18T14:04:10.488235Z","shell.execute_reply":"2023-05-18T14:04:10.491905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = CNN_Batchnorm_Aug_v2.fit(train_generator_aug, validation_data = validation_generator, epochs = 100, callbacks = [es])","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:54:49.172468Z","iopub.execute_input":"2023-05-18T10:54:49.172870Z","iopub.status.idle":"2023-05-18T13:40:33.929250Z","shell.execute_reply.started":"2023-05-18T10:54:49.172841Z","shell.execute_reply":"2023-05-18T13:40:33.927237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T13:51:55.243450Z","iopub.execute_input":"2023-05-18T13:51:55.244203Z","iopub.status.idle":"2023-05-18T13:51:55.249392Z","shell.execute_reply.started":"2023-05-18T13:51:55.244164Z","shell.execute_reply":"2023-05-18T13:51:55.248216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Accuracy vs Validation accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T13:51:59.639455Z","iopub.execute_input":"2023-05-18T13:51:59.640591Z","iopub.status.idle":"2023-05-18T13:51:59.959521Z","shell.execute_reply.started":"2023-05-18T13:51:59.640508Z","shell.execute_reply":"2023-05-18T13:51:59.958552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Loss vs Validation loss')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T13:52:08.262787Z","iopub.execute_input":"2023-05-18T13:52:08.263143Z","iopub.status.idle":"2023-05-18T13:52:08.537847Z","shell.execute_reply.started":"2023-05-18T13:52:08.263115Z","shell.execute_reply":"2023-05-18T13:52:08.536780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm_Aug_v2.save('fastfood_cnn_batchn_aug_v2.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, Y_test = get_images_to_predict(test_path, categories)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T13:54:12.823704Z","iopub.execute_input":"2023-05-18T13:54:12.824753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = CNN_Batchnorm_Aug_v2.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = probabilities_to_labels(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(Y_test, predictions)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm, cmap='Blues', xticklabels = categories, yticklabels = categories, annot = True, cbar = False, fmt=\".1f\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(Y_test, predictions)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen_aug_norm = ImageDataGenerator(rescale = 1./255,\n                                       rotation_range = 30,\n                                       width_shift_range = 0.1,\n                                       height_shift_range = 0.1,\n                                       fill_mode = 'nearest',\n                                       zoom_range = 0.1,\n                                       horizontal_flip = True,\n                                       vertical_flip = True)\n\ntrain_generator_aug_norm = train_datagen_aug_norm.flow_from_dataframe(train_df,\n                                                    x_col = 'path',\n                                                    y_col = 'label',\n                                                    target_size=(256,256),\n                                                    color_mode = 'rgb',\n                                                    classes = categories,\n                                                    batch_size = 32, \n                                                    class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:03:05.261836Z","iopub.execute_input":"2023-05-18T14:03:05.262399Z","iopub.status.idle":"2023-05-18T14:03:33.244371Z","shell.execute_reply.started":"2023-05-18T14:03:05.262356Z","shell.execute_reply":"2023-05-18T14:03:33.243478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm_Aug_v3 = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters = 32, kernel_size = (11,11), activation = 'relu', input_shape = (256, 256, 3)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 96, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 96, kernel_size = (5,5), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units = 1024, activation = 'relu'),\n    tf.keras.layers.Dense(units = 256, activation = 'relu'),\n    tf.keras.layers.Dense(units = 10, activation = 'softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:03:42.812012Z","iopub.execute_input":"2023-05-18T14:03:42.812754Z","iopub.status.idle":"2023-05-18T14:03:45.815351Z","shell.execute_reply.started":"2023-05-18T14:03:42.812705Z","shell.execute_reply":"2023-05-18T14:03:45.814332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm_Aug_v3.compile(loss = 'CategoricalCrossentropy', optimizer = tf.keras.optimizers.Adam(), metrics = 'accuracy')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:03:59.981497Z","iopub.execute_input":"2023-05-18T14:03:59.981847Z","iopub.status.idle":"2023-05-18T14:04:00.002516Z","shell.execute_reply.started":"2023-05-18T14:03:59.981817Z","shell.execute_reply":"2023-05-18T14:04:00.001631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = CNN_Batchnorm_Aug_v3.fit(train_generator_aug_norm, validation_data = validation_generator_norm, epochs = 100, callbacks = [es])","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:04:22.364121Z","iopub.execute_input":"2023-05-18T14:04:22.364485Z","iopub.status.idle":"2023-05-18T16:05:21.740718Z","shell.execute_reply.started":"2023-05-18T14:04:22.364456Z","shell.execute_reply":"2023-05-18T16:05:21.739824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Accuracy vs Validation accuracy')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Loss vs Validation loss')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_Batchnorm_Aug_v3.save('fastfood_cnn_batchn_aug_v3.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, Y_test = get_images_to_predict(test_path, categories, rescale = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = CNN_Batchnorm_Aug_v3.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = probabilities_to_labels(preds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(Y_test, predictions)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm, cmap='Blues', xticklabels = categories, yticklabels = categories, annot = True, cbar = False, fmt=\".1f\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(Y_test, predictions)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Zastosowanie większej ilości filtrów jak i normalizacja wartości pixeli nie przyniosła znacznie lepszych efektów.","metadata":{}},{"cell_type":"markdown","source":"Najlepszym klasyfikatorem okazała się sieć konwolucyjna z warstwami normalizacji wsadowej z dodatkowo zastosowaną augmentacją danych. Dokładność na zbiorze testowym wyniosła ok. 66%. Bardzo dużym problemem jest overfitting, którego finalnie nie udało się pozbyć mimo zastosowania kilku technik walki z nadmiernym dopasowaniem.","metadata":{}},{"cell_type":"markdown","source":"- https://keras.io/api/\n- https://www.tensorflow.org/api_docs/python/tf/all_symbols\n- https://scikit-learn.org/stable/\n- https://numpy.org/doc/stable/reference/index.html#reference\n- https://pandas.pydata.org/docs/\n- Francois Chollet 'Deep Learning. Praca z językiem Python i biblioteką Keras'\n- https://gist.github.com/ritiek/5fa903f97eb6487794077cf3a10f4d3e\n- https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n- https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/\n- https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/\n- https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n- https://neptune.ai/blog/how-to-choose-a-learning-rate-scheduler\n- https://optimization.cbe.cornell.edu/index.php?title=Adam\n- https://stackoverflow.com/questions/39517431/should-we-do-learning-rate-decay-for-adam-optimizer\n- https://pyimagesearch.com/2016/08/08/k-nn-classifier-for-image-classification/\n","metadata":{}}]}